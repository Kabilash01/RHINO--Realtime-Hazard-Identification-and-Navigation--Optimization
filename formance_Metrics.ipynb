{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python numpy scikit-learn matplotlib seaborn \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the path to the saved model\n",
    "model_path = \"C:/RHINO/inference_graph/saved_model\"\n",
    "\n",
    "# Load the model\n",
    "model = tf.saved_model.load(model_path)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Replace these with actual labels and predictions from your test dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Ground truth labels\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Replace these with actual labels and predictions from your test dataset\n",
    "y_true = np.array([1, 0, 1, 1, 0, 0, 1, 0, 1, 1])  # Ground truth labels\n",
    "y_pred = np.array([1, 0, 1, 0, 0, 1, 1, 0, 1, 1])  # Model predictions\n",
    "\n",
    "# Compute Performance Metrics\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Performance on Video ---\n",
      "Total Frames Processed: 0\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the TensorFlow saved model\n",
    "model_path = \"C:/vehicle-crash-detector/inference_graph/saved_model\"  # Adjust path\n",
    "model = tf.saved_model.load(model_path)\n",
    "infer = model.signatures[\"serving_default\"]  # Extract inference function\n",
    "\n",
    "# Define the video path\n",
    "video_path = \"C:\\vehicle-crash-detector\\test_videos\\test (1).mp4\"  # Replace with actual video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Define lists to store ground truth and predicted values\n",
    "y_true = []  # Actual crash labels (1 = crash, 0 = no_crash)\n",
    "y_pred = []  # Model predictions\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Stop when the video ends\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Preprocess frame\n",
    "    frame_resized = cv2.resize(frame, (640, 640))  # Adjust to match model input size\n",
    "    input_tensor = np.expand_dims(frame_resized, axis=0) / 255.0  # Normalize\n",
    "\n",
    "    # Run inference\n",
    "    output = infer(tf.convert_to_tensor(input_tensor, dtype=tf.float32))\n",
    "\n",
    "    # Process model output (Assuming model outputs crash probability)\n",
    "    crash_probability = output['output_0'].numpy()[0]  # Adjust key based on model output\n",
    "    predicted_label = 1 if crash_probability > 0.5 else 0  # Threshold at 50%\n",
    "\n",
    "    # Simulated ground truth labels (Replace with actual labels if available)\n",
    "    true_label = 1 if \"crash\" in video_path.lower() else 0  # Assume crash if filename contains \"crash\"\n",
    "    \n",
    "    y_pred.append(predicted_label)\n",
    "    y_true.append(true_label)\n",
    "\n",
    "    # Display frame with prediction\n",
    "    label_text = \"Crash\" if predicted_label == 1 else \"No Crash\"\n",
    "    color = (0, 0, 255) if predicted_label == 1 else (0, 255, 0)\n",
    "    cv2.putText(frame, f\"Prediction: {label_text}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Compute Performance Metrics\n",
    "precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n--- Model Performance on Video ---\")\n",
    "print(f\"Total Frames Processed: {frame_count}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip  install scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow opencv-python numpy scikit-learn matplotlib seaborn \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, confusion_matrix\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ðŸ”¹ Load the saved TensorFlow model\n",
    "model_path = \"C:/vehicle-crash-detector/inference_graph/saved_model\"  # Change this to your model path\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model path '{model_path}' does not exist. Check the path!\")\n",
    "\n",
    "model = tf.saved_model.load(model_path)\n",
    "infer = model.signatures[\"serving_default\"]  # Extract inference function\n",
    "print(\"\\nâœ… Model loaded successfully!\")\n",
    "\n",
    "# ðŸ”¹ Print model output keys to verify correct key\n",
    "print(\"\\nðŸ” Available model output keys:\", infer.structured_outputs.keys())\n",
    "\n",
    "# ðŸ”¹ Define the video path\n",
    "video_path = \"C:\\vehicle-crash-detector\\test_videos\\test (1).mp4\"  # Change this to your video path\n",
    "if not os.path.exists(video_path):\n",
    "    raise FileNotFoundError(f\"Video file '{video_path}' not found. Check the path!\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(\"âŒ Unable to open video file. Check the file format and codec!\")\n",
    "\n",
    "# ðŸ”¹ Define lists to store ground truth and predicted values\n",
    "y_true = []  # Actual crash labels (1 = crash, 0 = no_crash)\n",
    "y_pred = []  # Model predictions\n",
    "\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Stop when the video ends\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # ðŸ”¹ Preprocess frame\n",
    "    frame_resized = cv2.resize(frame, (640, 640))  # Adjust to match model input size\n",
    "    input_tensor = np.expand_dims(frame_resized, axis=0) / 255.0  # Normalize\n",
    "\n",
    "    # ðŸ”¹ Run inference\n",
    "    output = infer(tf.convert_to_tensor(input_tensor, dtype=tf.float32))\n",
    "\n",
    "    # ðŸ”¹ Process model output (Modify based on model output structure)\n",
    "    output_key = list(output.keys())[0]  # Auto-detect the first output key\n",
    "    crash_probability = output[output_key].numpy()[0]  # Modify if needed\n",
    "    predicted_label = 1 if crash_probability > 0.5 else 0  # Threshold at 50%\n",
    "\n",
    "    # ðŸ”¹ Simulated ground truth labels (Replace with actual labels if available)\n",
    "    true_label = 1 if \"crash\" in video_path.lower() else 0  # Assume crash if filename contains \"crash\"\n",
    "    \n",
    "    y_pred.append(predicted_label)\n",
    "    y_true.append(true_label)\n",
    "\n",
    "    # ðŸ”¹ Display frame with prediction\n",
    "    label_text = \"Crash\" if predicted_label == 1 else \"No Crash\"\n",
    "    color = (0, 0, 255) if predicted_label == 1 else (0, 255, 0)\n",
    "    cv2.putText(frame, f\"Prediction: {label_text}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.imshow(\"Vehicle Crash Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "end_time = time.time()\n",
    "\n",
    "# ðŸ”¹ Compute Performance Metrics (Check if we have valid predictions)\n",
    "if len(y_true) > 0 and len(y_pred) > 0:\n",
    "    precision = precision_score(y_true, y_pred, zero_division=1)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=1)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "else:\n",
    "    precision = recall = f1 = 0.0\n",
    "    print(\"\\nâš  No valid predictions were made. Metrics may not be accurate.\")\n",
    "\n",
    "# ðŸ”¹ Compute Inference Time\n",
    "total_time = end_time - start_time\n",
    "avg_inference_time = total_time / frame_count if frame_count else 0\n",
    "\n",
    "# ðŸ”¹ Print Performance Metrics\n",
    "print(f\"\\n--- Model Performance on Video ---\")\n",
    "print(f\"Total Frames Processed: {frame_count}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Average Inference Time per Frame: {avg_inference_time:.4f} seconds\")\n",
    "\n",
    "# ðŸ”¹ Generate Confusion Matrix (Only if data exists)\n",
    "if len(y_true) > 0 and len(y_pred) > 0:\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"No Crash\", \"Crash\"],\n",
    "                yticklabels=[\"No Crash\", \"Crash\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\nâš  No valid predictions. Skipping confusion matrix.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import required libraries after execution state reset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score, confusion_matrix\n",
    "\n",
    "# Simulated ground truth and predictions (Replace with actual values)\n",
    "y_true = np.random.randint(0, 2, 100)  # Replace with actual ground truth labels\n",
    "y_scores = np.random.rand(100)  # Replace with model's prediction confidence scores\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_scores > 0.5)\n",
    "\n",
    "# Compute precision-recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "average_precision = average_precision_score(y_true, y_scores)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=\"Blues\",\n",
    "            xticklabels=[\"No Crash\", \"Crash\"], yticklabels=[\"No Crash\", \"Crash\"])\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"Actual Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall Curve\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(recall, precision, marker='o', linestyle='-', color='blue', label=f\"AP={average_precision:.2f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# ðŸ”¹ Generate Synthetic Dataset (Simulating Reduced Visibility Conditions)\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "\n",
    "# Features: Visibility (m), Vehicle Speed (m/s), Headway Distance (m)\n",
    "visibility = np.random.uniform(50, 500, num_samples)  # Simulating low to high visibility\n",
    "speed = np.random.uniform(10, 40, num_samples)  # Vehicle speed in m/s\n",
    "distance = np.random.uniform(5, 50, num_samples)  # Headway distance in meters\n",
    "\n",
    "# ðŸ”¹ Define Collision Risk (1 = High Risk, 0 = Low Risk)\n",
    "collision_risk = ((speed / distance) > 0.8) & (visibility < 200)  # Higher risk if close and fast\n",
    "collision_risk = collision_risk.astype(int)  # Convert to binary classification\n",
    "\n",
    "# ðŸ”¹ Create DataFrame\n",
    "df = pd.DataFrame({\"Visibility\": visibility, \"Speed\": speed, \"Distance\": distance, \"CollisionRisk\": collision_risk})\n",
    "\n",
    "# ðŸ”¹ Split Data (80% Training, 20% Testing)\n",
    "X = df[[\"Visibility\", \"Speed\", \"Distance\"]]\n",
    "y = df[\"CollisionRisk\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ðŸ”¹ Normalize Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ðŸ”¹ Train a Neural Network (MLP Classifier)\n",
    "model = MLPClassifier(hidden_layer_sizes=(10, 5), activation=\"relu\", solver=\"adam\", max_iter=500, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ðŸ”¹ Predict on Test Data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# ðŸ”¹ Evaluate Model Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"âœ… Model Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nðŸ”¹ Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ðŸ”¹ Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"No Collision\", \"Collision\"], yticklabels=[\"No Collision\", \"Collision\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# ðŸ”¹ Plot Decision Boundary (Visibility vs Speed)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_test[\"Visibility\"], X_test[\"Speed\"], c=y_pred, cmap=\"coolwarm\", alpha=0.7, edgecolors=\"k\")\n",
    "plt.colorbar(label=\"Predicted Collision Risk (0=No, 1=Yes)\")\n",
    "plt.xlabel(\"Visibility (m)\")\n",
    "plt.ylabel(\"Speed (m/s)\")\n",
    "plt.title(\"Collision Prediction Based on Visibility and Speed\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
